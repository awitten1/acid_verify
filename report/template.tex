%%%% IACR Transactions TEMPLATE %%%%
% This file shows how to use the iacrtrans class to write a paper.
% Written by Gaetan Leurent gaetan.leurent@inria.fr (2020)
% Public Domain (CC0)


%%%% 1. DOCUMENTCLASS %%%%
\documentclass[journal=tosc,preprint]{iacrtrans}


\usepackage{tikz}
\usepackage{forest}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\raggedbottom

\usetikzlibrary{arrows.meta} % For nicer arrowheads

%%%% 3. AUTHOR, INSTITUTE %%%%
\author{Andrew Witten}
\institute{
  University of Maryland, College Park, USA \email{awitten1@umd.edu}
}
%%%% NOTES:
% - We need a city name for indexation purpose, even if it is redundant
%   (eg: University of Atlantis, Atlantis, Atlantis)


%%%% 4. TITLE %%%%
\title{Verifiable Database Transactions}

\begin{document}

\maketitle


%%%% 5. KEYWORDS %%%%
\keywords{Database systems \and Verifiable Computation}


%%%% 6. ABSTRACT %%%%
\begin{abstract}
In this work we present a database system which provides cryptographically verifiable ACID transactions. We provide a construction for a database that proves to its clients that it provides Serializability.
We evaluate our work by comparing the throughput
of our verified implementation against an unverified baseline and describe potential improvements to our system.

We additionally make our implementation available as an open source library \url{https://github.com/awitten1/acid_verify}.
\end{abstract}


%%%% 7. PAPER CONTENT %%%%
\section{Introduction}

A core feature of database systems is the provision of ACID transactions. This feature greatly simplifies application development by preventing race conditions, allowing developers to rely on these guarantees to maintain data correctness. However, database implementations often fail to meet these guarantees. The Jepsen project \cite{b1} has shown that many production databases fail to provide the consistency levels they claim. These errors can lead to data corruption, application failures, and security vulnerabilities.



Users currently have no way to verify that a database provider is executing transactions correctly; they must simply trust the provider's claims. This work addresses this problem. We present a construction for verifying that a database provides ACID transactions. In particular, we describe a Merkle-tree based system that proves to its clients that it provides Serializability.

\section{Background}
\subsection{Database Transactions}

Users of a database system submit transactions to the database system.  A transaction
is a sequence of reads and writes.  High performance systems run many transations concurrently from
many clients. Database systems provide ACID transactions. In this paper, we focus only on the Isolation property.
Isolation means that the database system provides a property called \textit{Serializability}.
Serializability means that transactions appear to execute sequentially
(even though the system may in reality run them concurrently).

In particular, suppose we have transactions
\(T_1,T_2,...,T_n\) running in the system.  Each \(T_i\) may be thought of as a function operating on the database
$T_i\colon D\rightarrow D$ (where \(D\) is the set of possible database states).  Serializability means that if \(d_{initial}\) is the inital state of the database
and \(d_{final}\) is the final state of the database, then $d_{final} = \left( T_{\pi(1)} \circ \dots \circ T_{\pi(n)} \right) \left( d_{initial} \right)$ where \(\pi\)
is a some permutation \cite{b2}.

This property is extremely value to developers because it allows developers to maintain invariants on their data.  If each $T_i$ maintains
an invariant, then the composition of them do as well.  For example client A may write a transaction transferring \$100 from user A to user B.
That transaction maintains the invariant that the total amount of money has stayed the same.  Client B might at the same time
write a transaction computing the total amount of money across all users.  Serializability guarantees that client B observes
the correct amount of money.

It is therefore paramount that database systems actually provide Isolation.  Failures to do so can (and will) lead to
application bugs (more doctors on call at the same time than is necessary \cite{b5}) or even security vulnerabilities \cite{b6}.
Despite their importance, database providers for one reason or another (bugs or deliberately) fail to provide the isolation levels
that users request.  Making matters worse, users usually have little or no ability to detect when a database provider has failed
to provide Serializability.  The goal of this work is to provide cryptographic proof that Serializability has been provided.

\subsection{Merkle Trees}

This work depends heavily on Merkle Trees. We therefore review Merkle Trees here and describe which properties we depend on.

\begin{figure}[htbp]
  \centering
  % Forest configuration
  \begin{forest}
    for tree={
      draw,              % Draw boxes around nodes
      circle,            % Make nodes circular (remove for rectangles)
      minimum size=2.5em,% Uniform size
      inner sep=1pt,     % Padding
      edge={-Stealth},   % Arrow style (remove for plain lines)
      l sep=1cm,         % Vertical distance between levels
      s sep=1cm,         % Horizontal distance between nodes
      font=\small
    }
    % The Tree Structure (Brackets define nesting)
    [$H_{root}$
      [$H_{01}$
        [$H_0$
          [$L_0$]
        ]
        [$H_1$
          [$L_1$]
        ]
      ]
      [$H_{23}$
        [$H_2$
          [$L_2$]
        ]
        [$H_3$
          [$L_3$]
        ]
      ]
    ]
  \end{forest}
  \caption{A Merkle Hash Tree structure.}
  \label{fig:merkle}
\end{figure}

A merkle tree is depicted in \autoref{fig:merkle}.  A merkle tree \cite{b8} is a binary tree of depth $\log n$.
A given node of a merkle tree stores a hash of its two children, for example $H_{01} = \text{Hash}\left(H_0 \| H_1\right)$
and $H_0 = \text{Hash}\left(L_0\right)$.

Assume now that a server is storing a set of data items $x_1\dots x_n$ and a client is only storing $H_{root}$, where the
merkle tree is built over the $x_i$.
The server is able to prove to the client that a given $x_i$ is stored on the server by providing the nodes
adjacent to the path from $x_i$ to the root in the tree.
These nodes allow a client to recompute the root of the tree and compare it against the root is has stored.
This proof is depicted in \autoref{fig:merkle_proof}.  The size of such a proof is $O\left(\log n\right)$.

\begin{figure}[htbp]
  \centering
  % Forest configuration
  \begin{forest}
    for tree={
      draw,              % Draw boxes around nodes
      circle,            % Make nodes circular (remove for rectangles)
      minimum size=2.5em,% Uniform size
      inner sep=1pt,     % Padding
      edge={-Stealth},   % Arrow style (remove for plain lines)
      l sep=1cm,         % Vertical distance between levels
      s sep=1cm,         % Horizontal distance between nodes
      font=\small
    }
    % The Tree Structure (Brackets define nesting)
    [$H_{root}$, dotted
      [$H_{01}$, fill=red!30
        [$H_0$
          [$L_0$]
        ]
        [$H_1$
          [$L_1$]
        ]
      ]
      [$H_{23}$, dotted
        [$H_2$, dotted
          [$L_2$]
        ]
        [$H_3$, fill=red!30
          [$L_3$]
        ]
      ]
    ]
  \end{forest}
  \caption{A Merkle Tree proof.  To prove that $L_2$ is stored in the tree, the server sends the nodes in red,
  which allow a client to recompute the root.}
  \label{fig:merkle_proof}
\end{figure}

\section{Related Work}

Verifiable database research has two main categories: verifying analytic queries and ensuring transactional correctness. Systems like zkSQL \cite{b3} and vSQL \cite{b4} target the former, using Zero-Knowledge proofs to authenticate complex SQL query results. However, they do not address the other main correctness concern: ACID transactions.

LitmusDB \cite{b7} is the state of the art system which uses RSA accumulators to provide constant-sized proofs and efficient key non-existence checks.
Additionally, LitmusDB employs "Deterministic Reservation" concurrency control to batch non-conflicting transactions,
aggregating their proofs into a single witness. The primary drawback of this concurrency control is that it does not allow for interactive transactions
(transactions for which the read/write set is not known ahead of time), however that is not a fundamental requirement of that system.

\section{Approach}

\subsection{Construction}

In this work we implement a kv-store where each transaction is a series of Get and Put operations.

The main idea of our construction follows from the definition of serializability, which we repeat here, that
that \(d_{final} = \left( T_{\pi(1)} \circ \dots \circ T_{\pi(n)} \right) \left( d_{initial} \right)\).
We associate with each intermediate state of the database a merkle tree $MT_k$ which
is computed on the prefix $\left( T_{\pi(1)} \circ \dots \circ T_{\pi(k)} \right) \left( d_{initial} \right)$.

We assume that clients of the database know the initial merkle tree of the database $MT_0$.  This can either
be computed ahead of time when data is initially uploaded, or we can assume that the database is initially empty
and the merkle tree is the empty merkle tree.

On transaction commit, the server now needs to provide a proof of two things:
\begin{enumerate}[nosep]
  \item All reads that occurred in transaction $\pi\left(k\right)$ were present in merkle tree $MT_{k-1}$
  \item The transition from $MT_{k-1}$ to $MT_{k}$ is valid based on the writes that have occurred in transaction $\pi\left(k\right)$
\end{enumerate}

The first of those is implemented by returning a list of merkle tree proofs that $MT_{k-1}$ contains all
values read.  The size of this proof is size $O(R\log n)$ where $R$ is the number of values read.  The client can then
prove to itself that all the values it read were in that snapshot of the database.  This linear factor of $R$
is only acceptable in transactional workloads where only a few records are updated in a transaction.

The second of those is implemented by returning a list of merkle tree proofs for all preimages of keys written.
Suppose the set of writes $W=\{\left(k_1,v_1\right),...,\left(k_w,v_w\right)\}$ where the transaction performs $w$ writes.
We return merkle tree proofs for each of the previous values of the keys.  These merkle tree proofs allow us to compute
what the next version of the tree will be given the writes we performed.

As a result the total size of the proof returned by the server is $O((W+R)\log n)$.  In an analytic workload where millions
of records could be read at a time this is not acceptable, but for a transactional workload, it may be acceptable.

This algorithm is sketched in \autoref{alg:verify}.

\begin{algorithm}[t]
\caption{Client-Side Transaction Verification}
\label{alg:verify}
\begin{algorithmic}[1]
\State \textbf{Input:} Old Root $R_{old}$, New Root $R_{new}$
\State \textbf{Input:} Read Set $S_R = \{(k, v)\}$, Proofs $\Pi_R$
\State \textbf{Input:} Write Set $S_W = \{(k, v)\}$, Proofs $\Pi_W$
\For{each $(k_i, v_i)$ in $S_R$}
    \State $\pi_i \gets \Pi_R[i]$
    \State $h_{leaf} \gets \text{Hash}(k_i\|v_i)$
    \State $computed\_root \gets \text{ComputeRoot}(h_{leaf}, \pi_i)$
    \If{$computed\_root \neq R_{old}$}
        \Return \textbf{False}
    \EndIf
\EndFor
\Statex
\State
\State $curr\_root \gets R_{old}$
\For{each $(k_j, v_j)$ in $S_W$}
    \State $\pi_j \gets \Pi_W[j]$
    \State $h_{new\_leaf} \gets \text{Hash}(k_k\|v_j)$
    \State $curr\_root \gets \text{ComputeRoot}(h_{new\_leaf}, \pi_j)$
\EndFor
\Statex
\If{$curr\_root == R_{new}$}
    \Return \textbf{True}
\Else
    \Return \textbf{False}
\EndIf
\end{algorithmic}
\end{algorithm}

\subsection{Implementation}

The API we implement is overviewed in \autoref{lst:api}. Users begin transactions, then execute a series of get and put
operations from a single thread on those transactions.  Currently the system has a global lock on that database that is
acquired when a transaction begins.  It supports serializability because only a single transaction can execute at a time
but also provides suboptimal peformance.  A high performance system would use a concurency
control protocol such as two phase locking \cite{b9}, MVCC, or OCC \cite{b2}.  We discuss this further in the future work section.


On transaction commit, our system does the following:
\begin{enumerate}[nosep]
  \item Generate proofs for all reads on merkle tree.
  \item Generate proofs for all writes on the merkle tree.
  \item Apply all writes to the database (organized as a B-tree).
  \item Fully reconstruct the merkle tree.
  \item Returns a proof object containing all proofs for reads and writes, the original merkle tree root, and the new merkle tree root.
\end{enumerate}


This allows the client to prove that reads on the original merkle tree were correct.
It also allows the client
to prove that the transition from the old merkle tree
to the new merkle tree was a valid transition.

The glaring issue with that protocol is that fully reconstructing
the merkle tree is an $O\left(n\right)$ operation and
is the primary bottleneck in the implementation.
There is no fundamental reason for requiring this though, it is possible
for merkle trees to support updating leaves.
However, standard merkle tree implementations do not generally support updates
(our implementation uses the Rust rs\_merkle \cite{b10} implementation).
We discuss as future work improvements in this area.

 \begin{minipage}{\textwidth}
\begin{lstlisting}[caption={API overview}, label={lst:api}]
impl DB {
  pub fn begin(&self) -> Transaction;
}

impl Transaction {
  pub fn get(&mut self, key: &str) -> Option<String>;
  pub fn put(&mut self, key: &str, value: &str);
  pub fn commit(mut self) -> Proof;
}
\end{lstlisting}
\end{minipage}

\section{Evaluation}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=60mm]{linegraph.png}
    \caption{This compares the throughput of an unverified transactional kv-store with a verified transactional kv-store.}
    \label{fig:comparison}
\end{figure}

For evaluation we compare our key value store when it generates proofs of transactionality and when it does not.
\autoref{fig:comparison} compares the throughput.  As mentioned before, our key-value store is effectively a
single-threaded in-memory system as we have implemented it.  Therefore a single core is constantly at 100\% utilization while
these experiments run.  The performance of the non-verified key-value store is directly related to the
single thread performance of CPU that this was run on (this was run on a MacBook Pro M2 Core) and the Rust standard library B-tree
implementation.

The performance of the verified key-value store is dominated by recomputing the merkle tree of the data after every transaction.

\section{Future Work}

There are two primary areas for improvement in our implementation: 1) since there is a global database lock, our database is effectively single-threaded
and therefore cannot utilize multi-core CPUs and 2) the merkle tree implementation is suboptimal and imposes significant CPU overhead.

The first of those issues can potentially be solved by integrating the system with a more sophisticated concurency control protocol
such as two phase locking, OCC, or MVCC, although there is complexity here.

It is possible to address the second of those issues with a higher performance merkle tree.  The state of the art here is the Sparse Merkle
Tree \cite{b11} or the Merkle Patricia Tree, which is used in Ethereum \cite{b12}.

\section{Conclusion}

We have presented a construction for cryptographically verifying
that database systems provide serializable transactions.
While our current implementation demonstrates the feasibility of this approach,
significant engineering work remains to achieve production-ready performance.
Nevertheless, this work establishes that verifiable ACID transactions are achievable with reasonable proof sizes
for transactional workloads (which read and write only a few records in a transaction),
opening the possibilty for more trustworthy database systems.


%\begin{samepage}
\begin{thebibliography}{99}
\bibitem{b1} K. Kingbury https://jepsen.io/analyses Jepsen Analyses
\bibitem{b2} H.T. Kung and John T. Robinson, On Optimistic Methods for Concurrency Control
\bibitem{b3} X. Li, C. Weng, Y. Xu, X. Wang, and J. Rogers, ZKSQL: Verifiable and Efficient Query Evaluation with Zero-Knowledge Proofs
\bibitem{b4} Y. Zheng et al, vSQL: Verifying Arbitrary SQL Queries over Dynamic Outsourced Databases
\bibitem{b5} Cahill et al, Serializable Isolation for Snapshot Databases
\bibitem{b6} T. Warszawski and P. Bailis, ACIDRain: Concurrency-Related Attacks on Database-Backed Web Applications
\bibitem{b7} Y. Xia, X. Yu, M. Butrovich, A. Pavlo, and S. Devadas, Litmus: Towards a Practical Database Management System with Verifiable ACID Properties and Transaction Correctness
\bibitem{b8} J. Katz and Y. Lindell, Introduction To Modern Cryptography
\bibitem{b9} P. A. Bernstein, V. Hadzilacos, and N. Goodman, Concurrency Control and Recovery in Database Systems
\bibitem{b10} https://github.com/antouhou/rs-merkle
\bibitem{b11} R. Dahlberg1, T. Pulls1, and R. Peeters2, Efficient Sparse Merkle Trees
\bibitem{b12} https://ethereum.org/developers/docs/data-structures-and-encoding/patricia-merkle-trie/

\end{thebibliography}
%\end{samepage}

\end{document}
